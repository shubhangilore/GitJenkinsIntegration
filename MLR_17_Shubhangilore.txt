# -*- coding: utf-8 -*-
"""
Created on Sat May 22 14:16:06 2021

@author: Shubhangi
"""

import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
import seaborn as sns
import utils

##############################################################
# Read Data 
##############################################################

df = pd.read_csv('D:\ML\Exam/california-housing.csv')

##############################################################
# Exploratory Data Analytics
##############################################################

print("\n*** Columns ***")
print(df.columns)

print("\n*** Structure ***")
print(df.info())

print("\n*** Summary ***")
print(df.describe())

print("\n*** Head ***")
print(df.head())

##############################################################
# Dependent Variable 
##############################################################

depVars = 'median_house_value'
print("\n*** Dep Vars ***")
print(depVars)

##############################################################
# Data Transformation
##############################################################

print("\n*** Drop Cols ***")
df = df.drop('ser', axis=1)
print("Done ...")


    
print('\n*** Outlier Count ***')
print(utils.OutlierCount(df))

print('\n*** Outlier Values ***')
print(utils.OutlierValues(df))

print('\n*** Variance In Columns ***')
print(df.var())

print('\n*** StdDev In Columns ***')
print(df.std())

print('\n*** Mean In Columns ***')
print(df.mean())

print('\n*** Columns With Zeros ***')
print((df==0).sum())

print('\n*** Columns With Nulls ***')
print(df.isnull().sum()) 





print("\n*** Transformations ***")
colName='housing_median_age'
if(int(df[colName].median())<int(df[colName].mean())):
    df[colName] = df[colName].fillna(df[colName].median())
else:
    df[colName] = df[colName].fillna(df[colName].mean())
    

colName='total_rooms'
if(int(df[colName].median())<int(df[colName].mean())):
    df[colName] = df[colName].fillna(df[colName].median())
else:
    df[colName] = df[colName].fillna(df[colName].mean())



colName='total_bedrooms'
if(int(df[colName].median())<int(df[colName].mean())):
    df[colName] = df[colName].fillna(df[colName].median())
else:
    df[colName] = df[colName].fillna(df[colName].mean())




colName='median_income'
df[colName] = df[colName].interpolate(method ='linear', limit_direction ='forward') 
df[colName] = df[colName].astype(int)


# colName='educated'
# if(int(df[colName].median())<int(df[colName].mean())):
#     df[colName] = df[colName].fillna(df[colName].median())
# else:
#     df[colName] = df[colName].fillna(df[colName].mean())



df['ocean_proximity'] = np.where(df['ocean_proximity']=='ISLAND',"INLAND",df['ocean_proximity'])
df['ocean_proximity'] = np.where(df['ocean_proximity']=='NEAR OCEAN',"NEAR BAY", df['ocean_proximity'])

df['ocean_proximity'] = df['ocean_proximity'].map({"NEAR BAY": 0, "<1H OCEAN": 1, "INLAND": 2})
print("***Done.....***")

print('\n*** Dropping Columns With greater than 30% Nulls values***')
df = df.drop('educated', axis=1)
print("Done ...")

print("\n*** Correlation Table ***")
pd.options.display.float_format = '{:,.2f}'.format
dfc = df.corr()
print("Done ...")

print("\n*** handle multi colinearity ***")
df = df.drop('longitude', axis=1)
print("Done ...")

##############################################################
# Visual Data Analytics
##############################################################

print("\n*** Heat Map ***")
plt.figure(figsize=(8,8))
ax = sns.heatmap(df.corr(), annot=True, cmap="PiYG")
bottom, top = ax.get_ylim()
ax.set_ylim(bottom+0.5, top-0.5)
plt.show()

print('\n*** Boxplot ***')
colNames = df.columns.tolist()
for colName in colNames:
    plt.figure()
    sns.boxplot(y=df[colName], color='b')
    plt.title(colName)
    plt.ylabel(colName)
    plt.xlabel('Bins')
    plt.show()

print('\n*** Histograms ***')
colNames = df.columns.tolist()
for colName in colNames:
    colValues = df[colName].values
    plt.figure()
    sns.distplot(colValues, bins=7, kde=False, color='b')
    plt.title(colName)
    plt.ylabel(colName)
    plt.xlabel('Bins')
    plt.show()

print('\n*** Scatterplot ***')
colNames = df.columns.tolist()
colNames.remove(depVars)
print(colName)
for colName in colNames:
    colValues = df[colName].values
    plt.figure()
    sns.regplot(data=df, x=depVars, y=colName, color= 'b', scatter_kws={"s": 5})
    plt.title(depVars + ' v/s ' + colName)
    plt.show()

colNames = ["ocean_proximity"]
print("\n*** Distribution Plot ***")
for colName in colNames:
    plt.figure()
    sns.countplot(df[colName],label="Count")
    plt.title(colName)
    plt.show()


###############################
# Split Train & Test
###############################

print("\n*** Prepare Data ***")
dfTrain = df.sample(frac=0.8, random_state=707)
dfTest=df.drop(dfTrain.index)
print("Train Count:",len(dfTrain.index))
print("Test Count :",len(dfTest.index))

##############################################################
# Model Creation & Fitting 
##############################################################

print("\n*** Regression Data ***")
allCols = dfTrain.columns.tolist()
print(allCols)
allCols.remove(depVars)
print(allCols)
print("Done ...")

print("\n*** Regression Summary ***")
import statsmodels.api as sm
X = sm.add_constant(dfTrain[allCols])
y = dfTrain[depVars]
OlsSmry = sm.OLS(y, X)
LRModel = OlsSmry.fit()
print(LRModel.summary())

print("\n*** Drop Cols ***")
allCols.remove('random_income')
print(allCols)

print("\n*** Regression Summary Again ***")
X = sm.add_constant(dfTrain[allCols])
y = dfTrain[depVars]
OlsSmry = sm.OLS(y, X)
LRModel = OlsSmry.fit()
print(LRModel.summary())

print("\n*** Regression Data For Train ***")
X_train = dfTrain[allCols].values
y_train = dfTrain[depVars].values
print(X_train.shape)
print(y_train.shape)
print(type(X_train))
print(type(y_train))
print("Done ...")

print("\n*** Regression Data For Test ***")
X_test = dfTest[allCols].values
y_test = dfTest[depVars].values
print(X_test.shape)
print(y_test.shape)
print(type(X_test))
print(type(y_test))
print("Done ...")


###############################
# Auto Select Best Regression
###############################


print("\n*** Import Regression Libraries ***")
from sklearn.linear_model import LinearRegression 
from sklearn.linear_model import Ridge 
from sklearn.linear_model import Lasso 
from sklearn.linear_model import ElasticNet 
print("Done ...")
  
print("\n*** Init Empty Lists ***")
lModels = []
lModelAdjR2 = []
lModelRmses = []
lModelScInd = []
lModelCoefs = []
print("Done ...")

print("\n*** Init Models Lists ***")
lModels.append(("LinearRegression", LinearRegression()))
lModels.append(("RidgeRegression ", Ridge(alpha = 10)))
lModels.append(("LassoRegression ", Lasso(alpha = 1)))
lModels.append(("ElasticNet      ", ElasticNet(alpha = 1)))
print("Done ...")

from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error

for vModelName, oModelObject in lModels:
    
    model = oModelObject
    
    print("\n*** "+vModelName)
    
    model.fit(X_train, y_train) 
    
    y_pred = model.predict(X_train)
    dfTrain[vModelName] = y_pred
    
    y_pred = model.predict(X_test)
    dfTest[vModelName] = y_pred
    
    r2 = r2_score(dfTrain[depVars], dfTrain[vModelName])
    print("R-Square:",r2)
    
    adj_r2 = (1 - (1 - r2) * ((X_train.shape[0] - 1) / 
              (X_train.shape[0] - X_train.shape[1] - 1)))
    lModelAdjR2.append(adj_r2)
    print("Adj R-Square:",adj_r2)
    
    mae = mean_absolute_error(dfTest[depVars], dfTest[vModelName])
    print("MAE:",mae)
    
    mse = mean_squared_error(dfTest[depVars], dfTest[vModelName])
    print("MSE:",mse)
    
    rmse = np.sqrt(mse)
    lModelRmses.append(rmse)
    print("RMSE:",rmse)

    si = rmse/dfTest[depVars].mean()
    lModelScInd.append(si)
    print("SI:",si)

msg = "%10s %16s %10s %10s" % ("Model Type", "AdjR2", "RMSE", "SI")
print(msg)
for i in range(0,len(lModels)):
    msg = "%16s %10.3f %10.3f %10.3f" % (lModels[i][0], lModelAdjR2[i], lModelRmses[i], lModelScInd[i])
    print(msg)


print("\n*** Best Model ***")
vBMIndex = lModelAdjR2.index(max(lModelAdjR2))
print("Index       : ",vBMIndex)
print("Model Name  : ",lModels[vBMIndex][0])
print("Adj-R-Sq    : ",lModelAdjR2[vBMIndex])
print("RMSE        : ",lModelRmses[vBMIndex])
print("ScatterIndex: ",lModelScInd[vBMIndex])


##############################################################
# predict from new data 
##############################################################

print(allCols)

print("\n*** Regression Summary Again ***")
X = sm.add_constant(df[allCols])
y = df[depVars]
OlsSmry = sm.OLS(y, X)
LRModel = OlsSmry.fit()
print(LRModel.summary())

print("\n*** Regression Model ***")
X = df[allCols].values
y = df[depVars].values
model = lModels[vBMIndex][1]
model.fit(X,y)
print(model)

dfp = pd.read_csv('D:\ML\Exam/california-housing-prd.csv')

print("\n*** Structure ***")
print(dfp.info())

print("\n*** Drop Cols ***")
dfp = dfp.drop('ser', axis=1)
print("Done ...")

print("\n*** Transformations ***")
colName='housing_median_age'
if(int(dfp[colName].median())<int(dfp[colName].mean())):
    dfp[colName] = dfp[colName].fillna(dfp[colName].median())
else:
    dfp[colName] = dfp[colName].fillna(dfp[colName].mean())
    
colName='total_bedrooms'
if(int(dfp[colName].median())<int(dfp[colName].mean())):
    dfp[colName] = dfp[colName].fillna(dfp[colName].median())
else:
    dfp[colName] = dfp[colName].fillna(dfp[colName].mean())

# colName='educated'
# if(int(dfp[colName].median())<int(dfp[colName].mean())):
#     dfp[colName] = dfp[colName].fillna(dfp[colName].median())
# else:
#     dfp[colName] = dfp[colName].fillna(dfp[colName].mean())
    
colName='total_rooms'
if(int(df[colName].median())<int(df[colName].mean())):
    dfp[colName] = dfp[colName].fillna(dfp[colName].median())
else:
    dfp[colName] = dfp[colName].fillna(dfp[colName].mean())

colName='median_income'
dfp[colName] = dfp[colName].interpolate(method ='linear', limit_direction ='forward') 
dfp[colName] = dfp[colName].astype(int)


dfp['ocean_proximity'] = np.where(dfp['ocean_proximity']=='ISLAND',"INLAND",dfp['ocean_proximity'])
dfp['ocean_proximity'] = np.where(dfp['ocean_proximity']=='NEAR OCEAN',"NEAR BAY", dfp['ocean_proximity'])

dfp['ocean_proximity'] = dfp['ocean_proximity'].map({"NEAR BAY": 0, "<1H OCEAN": 1, "INLAND": 2})
print("***Done.....***")

print('\n*** Dropping Columns With greater than 30% Nulls values***')
dfp = dfp.drop('educated', axis=1)
print("Done ...")

print("\n*** handle multi colinearity ***")
dfp = dfp.drop('longitude', axis=1)
print("Done ...")

print("\n*** Split Predict Data ***")
X_pred = dfp[allCols].values
y_pred = dfp[depVars].values
print(X_pred)
print(y_pred)

print("\n*** Predict Data ***")
p_pred = model.predict(X_pred)
dfp['median_house_value'] = p_pred
print("Done ... ")

print("\n*** Scatter Plot ***")
plt.figure()
sns.regplot(x=y_pred, y=p_pred, color= 'b')
plt.show()

print("\n*** Mean Absolute Error ***")
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_pred, p_pred)
print(mae)

print("\n*** Mean Squared Error ***")
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_pred, p_pred)
print(mse)

print("\n*** Root Mean Squared Error ***")
rmse = np.sqrt(mse)
print(rmse)

print('\n*** Mean ***')
print(y_pred.mean())
print(p_pred.mean())

print('\n*** Scatter Index ***')
si = rmse/y_pred.mean()
print(si)

###############Exporting#############################

dfp.to_csv('D:\ML\Exam/PRD-17-Shubhangi_Lore.csv')